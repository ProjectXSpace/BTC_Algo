{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ta\n",
    "import talib\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the window size and threshold percentage\n",
    "df = pd.read_csv('BTC-USD')\n",
    "window_size = 10 # 5 days befor and 5 days after\n",
    "threshold_percentage = 5  # 5% change\n",
    "\n",
    "# Calculate the threshold_value as a percentage of the closing price\n",
    "threshold_value = df['Close'] * threshold_percentage / 100\n",
    "\n",
    "# Initialize a column for combined refined minima and maxima with percentage threshold\n",
    "df['label'] = 0\n",
    "\n",
    "# Loop through the dataframe and apply the combined condition with percentage threshold\n",
    "for i in range(window_size, len(df) - window_size):\n",
    "    current_window = df['Close'].iloc[i - window_size//2 : i + window_size//2 + 1]\n",
    "    current_point = df['Close'].iloc[i]\n",
    "    \n",
    "    # Check if current point is minima or maxima in the window\n",
    "    if current_point == min(current_window) and abs(current_point - max(current_window)) > threshold_value.iloc[i]:\n",
    "        df.at[i, 'label'] = -1\n",
    "    elif current_point == max(current_window) and abs(current_point - min(current_window)) > threshold_value.iloc[i]:\n",
    "        df.at[i, 'label'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropped noisy periods and created the encoded column called label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.read_csv('Encoded_BTC.csv', index_col='Date', parse_dates=True)\n",
    "\n",
    "# main_df = main_df.loc['2020-09-15':'2022-08-01'].drop(columns=['Unnamed: 0', 'Adj Close'])\n",
    "\n",
    "\n",
    "# Plotting the data from main_df\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(main_df.index, main_df['Close'], label='Closing Price', alpha=0.7)\n",
    "if 'label' in main_df.columns:\n",
    "    plt.scatter(main_df.index[main_df['label'] == -1], main_df['Close'][main_df['label'] == -1], color='green', label='Minima (-1)')\n",
    "    plt.scatter(main_df.index[main_df['label'] == 1], main_df['Close'][main_df['label'] == 1], color='blue', label='Maxima (1)')\n",
    "plt.title('Test Data: Closing Prices with Minima and Maxima')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(main_df['label'].value_counts())\n",
    "main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(ticker, feature_lags=[3, 8, 14]):\n",
    "    \"\"\"\n",
    "    Calculate a variety of metrics for a given stock ticker, including moving averages, rate of change (ROC),\n",
    "    on-balance volume (OBV), and the relative strength index (RSI). Also calculates lagged versions of these metrics\n",
    "    based on the `lags` input.\n",
    "\n",
    "    Args:\n",
    "        ticker (str): The stock ticker to calculate metrics for.\n",
    "        period (int): The period to use for calculating metrics.\n",
    "        threshold (float): The threshold to use for calculating metrics.\n",
    "        lags (list of int): The lag periods to use for calculating lagged metrics.\n",
    "        refresh (bool, optional): Whether to refresh the data. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame with the calculated metrics and labels.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(\"Encoded_BTC.csv\", parse_dates=True, index_col='Date')\n",
    "\n",
    "    main_df = df.loc['2020-09-15':'2022-08-01'].drop(columns=['Unnamed: 0', 'Adj Close'])\n",
    "\n",
    "    main_df.columns = [f'BTC_{column}' for column in main_df.columns]\n",
    "\n",
    "\n",
    "    metrics_df = pd.DataFrame()\n",
    "\n",
    "    # Calculate base metrics\n",
    "    rsi = ta.momentum.RSIIndicator(main_df[f\"{ticker}_Close\"], window=14).rsi()\n",
    "    metrics_df[f\"{ticker}_RSI\"] = rsi.shift(periods=1)\n",
    "\n",
    "\n",
    "    rolling_std_shifted = main_df[f\"{ticker}_Close\"].rolling(window=20).std().shift(periods=1)\n",
    "    metrics_df[f\"{ticker}_Bollinger_Up\"] = (main_df[f\"{ticker}_Close\"].rolling(window=20).mean().shift(periods=1) + 2 * rolling_std_shifted)\n",
    "    metrics_df[f\"{ticker}_Bollinger_Down\"] = (main_df[f\"{ticker}_Close\"].rolling(window=20).mean().shift(periods=1) - 2 * rolling_std_shifted)\n",
    "\n",
    "    adx = talib.ADX(main_df[f\"{ticker}_High\"], main_df[f\"{ticker}_Low\"], main_df[f\"{ticker}_Close\"], timeperiod=14)\n",
    "    metrics_df[f\"{ticker}_ADX\"] = adx.shift(periods=1)\n",
    "\n",
    "    macd_line, signal_line, _ = talib.MACD(\n",
    "        main_df[f\"{ticker}_Close\"], fastperiod=12, slowperiod=26, signalperiod=9\n",
    "    )\n",
    "    metrics_df[f\"{ticker}_MACD\"] = (macd_line - signal_line).shift(periods=1)\n",
    "\n",
    "    obv = ta.volume.OnBalanceVolumeIndicator(\n",
    "        main_df[f\"{ticker}_Close\"], main_df[f\"{ticker}_Volume\"]\n",
    "    ).on_balance_volume()\n",
    "    metrics_df[f\"{ticker}_OBV\"] = obv.shift(periods=1)\n",
    "\n",
    "    # Calculate lagged metrics\n",
    "    for lag in feature_lags:\n",
    "        # Use shift to create lagged features, to avoid looking ahead in time\n",
    "        metrics_df[f\"{ticker}_Delta_ADX_{lag}\"] = adx.diff(lag).shift(periods=1)\n",
    "        \n",
    "        metrics_df[f\"{ticker}_MA_{lag}\"] = (\n",
    "            main_df[f\"{ticker}_Close\"].rolling(window=lag).mean().shift(periods=1)\n",
    "        )\n",
    "        metrics_df[f\"{ticker}_ROC_{lag}\"] = talib.ROC(\n",
    "            main_df[f\"{ticker}_Close\"], timeperiod=lag\n",
    "        ).shift(periods=1)\n",
    "        metrics_df[f\"{ticker}_OBV_ROC_{lag}\"] = obv.pct_change(periods=lag).shift(\n",
    "            periods=1\n",
    "        )\n",
    "        metrics_df[f\"{ticker}_Delta_RSI_{lag}\"] = rsi.diff(lag).shift(periods=1)\n",
    "\n",
    "    # Handle missing values\n",
    "    metrics_df = metrics_df.replace([np.inf, -np.inf], np.nan)\n",
    "    metrics_df.dropna(inplace=True)\n",
    "\n",
    "    final_df = metrics_df.join(main_df[f\"{ticker}_label\"])\n",
    "\n",
    "    # # Validate data types\n",
    "    assert set(final_df.dtypes) <= {np.dtype(\"float64\"), np.dtype(\"int64\")}, \"Unexpected data types in DataFrame\"\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_and_Y_for_ML(ticker, feature_lags=[ 9 ,14, 21, 25, 30], days_back = 100):\n",
    "    \n",
    "    df = calculate_metrics(\n",
    "        ticker, feature_lags=feature_lags)\n",
    "\n",
    "    X = df.drop(columns=[f\"{ticker}_label\"])\n",
    "    Y = df[f\"{ticker}_label\"].copy()\n",
    "\n",
    "    # Use all data except last day for training, and last day for testing\n",
    "    X_train, X_test, Y_train, Y_test = X[:-days_back], X[-days_back:], Y[:-days_back], Y[-days_back:]\n",
    "\n",
    "    # X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25)\n",
    "\n",
    "    # X_train, X_test, Y_train, Y_test = X_train.values, X_test.values, Y_train.values, Y_test.values\n",
    "\n",
    "    return X_train, X_test, Y_train, Y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-23 20:37:02.492907: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-23 20:37:02.747431: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-23 20:37:02.821691: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-23 20:37:03.073469: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-23 20:37:03.169164: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - ETA: 0s - loss: 1.1034 - accuracy: 0.4366 - precision: 0.0000e+00 - recall: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-23 20:37:04.167168: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-23 20:37:04.257563: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-23 20:37:04.310214: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 3s 80ms/step - loss: 1.1034 - accuracy: 0.4366 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0989 - val_accuracy: 0.2171 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 1s 32ms/step - loss: 1.1055 - accuracy: 0.5283 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0872 - val_accuracy: 0.3256 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 1.1086 - accuracy: 0.0955 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.2032 - val_accuracy: 0.0698 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.1034 - accuracy: 0.0565 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.1184 - val_accuracy: 0.1473 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.0931 - accuracy: 0.3216 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0595 - val_accuracy: 0.6047 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.0996 - accuracy: 0.5224 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0487 - val_accuracy: 0.6899 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.0850 - accuracy: 0.3489 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0865 - val_accuracy: 0.4031 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 1.0889 - accuracy: 0.2904 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0555 - val_accuracy: 0.5659 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.0899 - accuracy: 0.5945 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0417 - val_accuracy: 0.6589 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.0841 - accuracy: 0.5906 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0487 - val_accuracy: 0.5891 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.0877 - accuracy: 0.5634 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0375 - val_accuracy: 0.6667 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.0905 - accuracy: 0.4094 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0558 - val_accuracy: 0.4729 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.0777 - accuracy: 0.3938 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0406 - val_accuracy: 0.5891 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.0970 - accuracy: 0.6881 - precision: 1.0000 - recall: 0.0039 - val_loss: 1.0215 - val_accuracy: 0.6822 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.0903 - accuracy: 0.5575 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0621 - val_accuracy: 0.5271 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.0866 - accuracy: 0.3567 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0645 - val_accuracy: 0.4341 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.0817 - accuracy: 0.4971 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0404 - val_accuracy: 0.5891 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.0905 - accuracy: 0.4971 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0543 - val_accuracy: 0.4341 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.0926 - accuracy: 0.4912 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0438 - val_accuracy: 0.5659 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.0869 - accuracy: 0.5146 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0648 - val_accuracy: 0.5116 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.0883 - accuracy: 0.5458 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0630 - val_accuracy: 0.4264 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.0896 - accuracy: 0.2242 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.1133 - val_accuracy: 0.3643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.0854 - accuracy: 0.4444 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0137 - val_accuracy: 0.6822 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.0916 - accuracy: 0.5750 - precision: 1.0000 - recall: 0.0078 - val_loss: 1.0596 - val_accuracy: 0.4264 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.0876 - accuracy: 0.4678 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0547 - val_accuracy: 0.5504 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.0770 - accuracy: 0.5166 - precision: 1.0000 - recall: 0.0039 - val_loss: 1.0433 - val_accuracy: 0.5814 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.0929 - accuracy: 0.4561 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0987 - val_accuracy: 0.3566 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.1205 - accuracy: 0.0702 - precision: 0.0645 - recall: 0.0117 - val_loss: 1.2088 - val_accuracy: 0.0620 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.0864 - accuracy: 0.2105 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0964 - val_accuracy: 0.5194 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.0927 - accuracy: 0.2943 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.1202 - val_accuracy: 0.3023 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.0888 - accuracy: 0.2690 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0619 - val_accuracy: 0.5581 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.0908 - accuracy: 0.6355 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0344 - val_accuracy: 0.5659 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.0848 - accuracy: 0.4659 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0726 - val_accuracy: 0.4186 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.0855 - accuracy: 0.4055 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0899 - val_accuracy: 0.3953 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.0859 - accuracy: 0.1033 - precision: 0.0455 - recall: 0.0019 - val_loss: 1.1914 - val_accuracy: 0.0775 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 1.0919 - accuracy: 0.0702 - precision: 0.0571 - recall: 0.0039 - val_loss: 1.1473 - val_accuracy: 0.0775 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.0871 - accuracy: 0.1793 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0855 - val_accuracy: 0.2248 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 1.0845 - accuracy: 0.3548 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0752 - val_accuracy: 0.2636 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 1.0840 - accuracy: 0.3782 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0755 - val_accuracy: 0.2713 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.0877 - accuracy: 0.5770 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0484 - val_accuracy: 0.5814 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.0987 - accuracy: 0.2982 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.1135 - val_accuracy: 0.2403 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.0842 - accuracy: 0.1248 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.1081 - val_accuracy: 0.2713 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.0859 - accuracy: 0.2768 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0725 - val_accuracy: 0.3566 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.0843 - accuracy: 0.4659 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0603 - val_accuracy: 0.4729 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.0918 - accuracy: 0.1949 - precision: 0.0909 - recall: 0.0058 - val_loss: 1.1286 - val_accuracy: 0.0698 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.0889 - accuracy: 0.1267 - precision: 0.1111 - recall: 0.0078 - val_loss: 1.0990 - val_accuracy: 0.2016 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 1.0882 - accuracy: 0.1871 - precision: 0.0556 - recall: 0.0019 - val_loss: 1.0939 - val_accuracy: 0.2713 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.0800 - accuracy: 0.2437 - precision: 0.2000 - recall: 0.0019 - val_loss: 1.0778 - val_accuracy: 0.3023 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.0847 - accuracy: 0.3743 - precision: 0.3333 - recall: 0.0019 - val_loss: 1.0701 - val_accuracy: 0.4574 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 1.0827 - accuracy: 0.4113 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0670 - val_accuracy: 0.4109 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.0855 - accuracy: 0.4172 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0655 - val_accuracy: 0.4186 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 1.0791 - accuracy: 0.3723 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0655 - val_accuracy: 0.4729 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.0781 - accuracy: 0.4854 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0632 - val_accuracy: 0.5039 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 1.0799 - accuracy: 0.4444 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0710 - val_accuracy: 0.4031 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.0818 - accuracy: 0.3567 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0621 - val_accuracy: 0.4341 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 1.0809 - accuracy: 0.5439 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0313 - val_accuracy: 0.6434 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.0859 - accuracy: 0.4600 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0600 - val_accuracy: 0.5349 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.0792 - accuracy: 0.4932 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0421 - val_accuracy: 0.5814 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.0811 - accuracy: 0.4990 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0557 - val_accuracy: 0.5349 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 1.0942 - accuracy: 0.3548 - precision: 0.3333 - recall: 0.0019 - val_loss: 1.0761 - val_accuracy: 0.3798 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.0886 - accuracy: 0.4834 - precision: 0.5000 - recall: 0.0019 - val_loss: 1.0240 - val_accuracy: 0.6357 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.0889 - accuracy: 0.5828 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0713 - val_accuracy: 0.5039 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 1.0851 - accuracy: 0.1696 - precision: 0.2000 - recall: 0.0019 - val_loss: 1.1651 - val_accuracy: 0.1705 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 1.0881 - accuracy: 0.2359 - precision: 1.0000 - recall: 0.0019 - val_loss: 1.0614 - val_accuracy: 0.4651 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 1.0941 - accuracy: 0.4951 - precision: 0.8750 - recall: 0.0136 - val_loss: 1.0160 - val_accuracy: 0.6202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.0801 - accuracy: 0.4873 - precision: 1.0000 - recall: 0.0019 - val_loss: 1.0520 - val_accuracy: 0.5736 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.0778 - accuracy: 0.4990 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0450 - val_accuracy: 0.5891 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.0848 - accuracy: 0.4756 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0434 - val_accuracy: 0.5504 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 1.0843 - accuracy: 0.4542 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0500 - val_accuracy: 0.5581 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 1.0836 - accuracy: 0.4503 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0497 - val_accuracy: 0.5349 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.0718 - accuracy: 0.4581 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0375 - val_accuracy: 0.5814 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 1.0789 - accuracy: 0.4795 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0377 - val_accuracy: 0.5426 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.0799 - accuracy: 0.4737 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0400 - val_accuracy: 0.5504 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.0826 - accuracy: 0.4776 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0447 - val_accuracy: 0.5271 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.0846 - accuracy: 0.3684 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0471 - val_accuracy: 0.5116 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.0822 - accuracy: 0.5556 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0301 - val_accuracy: 0.5736 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.0781 - accuracy: 0.1969 - precision: 0.2000 - recall: 0.0039 - val_loss: 1.1671 - val_accuracy: 0.1783 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.1138 - accuracy: 0.0604 - precision: 0.0851 - recall: 0.0078 - val_loss: 1.1817 - val_accuracy: 0.0620 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.0891 - accuracy: 0.0604 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.1164 - val_accuracy: 0.1240 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.0916 - accuracy: 0.2573 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0691 - val_accuracy: 0.5891 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.0860 - accuracy: 0.4503 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0722 - val_accuracy: 0.6202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.0847 - accuracy: 0.4250 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0851 - val_accuracy: 0.5271 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.0852 - accuracy: 0.1852 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.1063 - val_accuracy: 0.1783 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.0875 - accuracy: 0.1248 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0935 - val_accuracy: 0.3566 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.0855 - accuracy: 0.2573 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0874 - val_accuracy: 0.3798 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.0922 - accuracy: 0.1014 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.2055 - val_accuracy: 0.0698 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 1.0965 - accuracy: 0.0643 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.1664 - val_accuracy: 0.0620 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.0854 - accuracy: 0.0624 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.1538 - val_accuracy: 0.0620 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.0879 - accuracy: 0.0682 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.1356 - val_accuracy: 0.0698 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.0784 - accuracy: 0.0721 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.1087 - val_accuracy: 0.0620 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.0849 - accuracy: 0.1481 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0862 - val_accuracy: 0.2868 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.0840 - accuracy: 0.1559 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0966 - val_accuracy: 0.2093 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.0811 - accuracy: 0.2339 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0727 - val_accuracy: 0.4806 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.0827 - accuracy: 0.3626 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0700 - val_accuracy: 0.4961 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.0763 - accuracy: 0.3314 - precision: 0.5000 - recall: 0.0019 - val_loss: 1.0766 - val_accuracy: 0.4109 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.0891 - accuracy: 0.4250 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0536 - val_accuracy: 0.5504 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.0864 - accuracy: 0.2242 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0968 - val_accuracy: 0.0620 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.0876 - accuracy: 0.0643 - precision: 0.1667 - recall: 0.0019 - val_loss: 1.1238 - val_accuracy: 0.0775 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.0846 - accuracy: 0.0643 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.1341 - val_accuracy: 0.0620 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 1.0827 - accuracy: 0.0702 - precision: 0.2500 - recall: 0.0019 - val_loss: 1.1055 - val_accuracy: 0.1628 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "1/5 [=====>........................] - ETA: 1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-23 20:37:47.285765: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-23 20:37:47.348409: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-23 20:37:47.402256: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "data = calculate_metrics('BTC')\n",
    "\n",
    "# 1. Scale the data\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data.drop('BTC_label', axis=1))\n",
    "\n",
    "labels = data['BTC_label'].values.reshape(-1, 1)  # use a different variable name for labels and reshape\n",
    "\n",
    "# One-hot encode the labels\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "encoded_labels = encoder.fit_transform(labels)\n",
    "\n",
    "# 2. Prepare sequences\n",
    "sequence_length = 10  # for example\n",
    "X, y_seq = [], []\n",
    "for i in range(len(data) - sequence_length):\n",
    "    X.append(scaled_data[i:i+sequence_length])\n",
    "    y_seq.append(encoded_labels[i + sequence_length])  # use encoded_labels here\n",
    "\n",
    "X = np.array(X)\n",
    "y_seq = np.array(y_seq)\n",
    "\n",
    "# 3. Calculate class weights\n",
    "unique_labels = np.unique(data['BTC_label'])\n",
    "class_weights = compute_class_weight('balanced', classes=unique_labels, y=data['BTC_label'])\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}  # adjust index for one-hot encoding\n",
    "\n",
    "# 4. Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_seq, test_size=0.2, shuffle=False)\n",
    "\n",
    "\n",
    "# 5. Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(50, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(25))\n",
    "model.add(Dense(3, activation='softmax'))  # Ensure 3 units for 3 classes\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', 'Precision', 'Recall'])  # We'll stick with accuracy for now\n",
    "\n",
    "# 6. Train the model\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_test, y_test), class_weight=class_weight_dict)\n",
    "\n",
    "# 7. Predict and evaluate\n",
    "predictions_LSTM = model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Convert one-hot encoded predictions to label values\n",
    "predicted_labels = np.argmax(predictions_LSTM, axis=1)\n",
    "true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', \n",
    "            xticklabels=['-1', '0', '1'], yticklabels=['-1', '0', '1'])\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
