{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import yfinance as yf\n",
    "from pandas_datareader import data as pdr\n",
    "import ta\n",
    "\n",
    "# import talib\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    HistGradientBoostingClassifier,\n",
    ")\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import traceback\n",
    "\n",
    "# from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import requests\n",
    "\n",
    "# from yahoo_fin import stock_info\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retreive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       MMM\n",
       "1       AOS\n",
       "2       ABT\n",
       "3      ABBV\n",
       "4       ACN\n",
       "       ... \n",
       "498     YUM\n",
       "499    ZBRA\n",
       "500     ZBH\n",
       "501    ZION\n",
       "502     ZTS\n",
       "Name: Symbol, Length: 503, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def save_sp500_tickers():\n",
    "    \"\"\"\n",
    "    Scrapes S&P500 tickers from Wikipedia.\n",
    "\n",
    "    Returns:\n",
    "        pandas.Series: A series of S&P500 tickers.\n",
    "    \"\"\"\n",
    "    df_tables = pd.read_html(\n",
    "        \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "    )\n",
    "    tickers = df_tables[0][\"Symbol\"]\n",
    "    return tickers\n",
    "\n",
    "\n",
    "save_sp500_tickers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data(ticker):\n",
    "    \"\"\"\n",
    "    Retrieves historical data for a given ticker.\n",
    "\n",
    "    Args:\n",
    "        ticker (str): The stock ticker.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A dataframe with historical data for the given ticker.\n",
    "    \"\"\"\n",
    "    start = datetime(2010, 1, 1)\n",
    "    end = datetime.now() - timedelta(days=1)\n",
    "\n",
    "    try:\n",
    "        yf.pdr_override()\n",
    "        df = pdr.get_data_yahoo(ticker, start, end)\n",
    "        df = df[[\"Open\", \"Close\", \"High\", \"Low\", \"Volume\"]]\n",
    "        df.columns = [\n",
    "            f\"{ticker}_Open\",\n",
    "            f\"{ticker}_Close\",\n",
    "            f\"{ticker}_High\",\n",
    "            f\"{ticker}_Low\",\n",
    "            f\"{ticker}_Volume\",\n",
    "        ]\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Could not retrieve data for {ticker}: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_save_combined_data():\n",
    "    \"\"\"\n",
    "    Retrieves historical data for all S&P500 tickers and saves the data to a CSV file.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    tickers = save_sp500_tickers()\n",
    "    data = []\n",
    "    with ThreadPoolExecutor(max_workers=1) as executor:\n",
    "        for result in executor.map(retrieve_data, tickers):\n",
    "            print(f\"Retrieved data for ticker with length {len(result)}\")\n",
    "            data.append(result)\n",
    "\n",
    "    combined_df = pd.concat(data, axis=1, join=\"outer\")\n",
    "\n",
    "    print(f\"Final combined DataFrame shape: {combined_df.shape}\")\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing grounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"fresh_data.csv\", parse_dates=True, index_col=0)\n",
    "ticker = \"AAPL\"\n",
    "lag = 3\n",
    "\n",
    "rolling_std_shifted = df[f\"{ticker}_Close\"].rolling(window=20).mean()\n",
    "\n",
    "rolling_std_shifted.mean()\n",
    "\n",
    "other_tickers = [\n",
    "            col[:-6]\n",
    "            for col in df.columns\n",
    "            if col.endswith(\"_Close\") and col != f\"{ticker}_Close\"\n",
    "        ]\n",
    "other_ma_lag = pd.concat(\n",
    "    [\n",
    "        df[f\"{other_ticker}_Close\"]\n",
    "        .pct_change()\n",
    "        .rolling(window=lag)\n",
    "        .mean()\n",
    "        .shift(periods=1)\n",
    "        for other_ticker in other_tickers\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "df[f\"Market_MA_{lag}\"] = other_ma_lag.mean(axis=1)\n",
    "\n",
    "other_ma_lag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create X and Y for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'fresh_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ivantrue/Desktop/Git/ProjectX_Algo/Models_with_stacking.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ivantrue/Desktop/Git/ProjectX_Algo/Models_with_stacking.ipynb#X11sZmlsZQ%3D%3D?line=112'>113</a>\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mset\u001b[39m(final_df\u001b[39m.\u001b[39mdtypes) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m {\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ivantrue/Desktop/Git/ProjectX_Algo/Models_with_stacking.ipynb#X11sZmlsZQ%3D%3D?line=113'>114</a>\u001b[0m         np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mfloat64\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ivantrue/Desktop/Git/ProjectX_Algo/Models_with_stacking.ipynb#X11sZmlsZQ%3D%3D?line=114'>115</a>\u001b[0m         np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mint64\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ivantrue/Desktop/Git/ProjectX_Algo/Models_with_stacking.ipynb#X11sZmlsZQ%3D%3D?line=115'>116</a>\u001b[0m     }, \u001b[39m\"\u001b[39m\u001b[39mUnexpected data types in DataFrame\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ivantrue/Desktop/Git/ProjectX_Algo/Models_with_stacking.ipynb#X11sZmlsZQ%3D%3D?line=117'>118</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m final_df\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/ivantrue/Desktop/Git/ProjectX_Algo/Models_with_stacking.ipynb#X11sZmlsZQ%3D%3D?line=120'>121</a>\u001b[0m calculate_metrics(\u001b[39m\"\u001b[39;49m\u001b[39mAAPL\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32m/Users/ivantrue/Desktop/Git/ProjectX_Algo/Models_with_stacking.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ivantrue/Desktop/Git/ProjectX_Algo/Models_with_stacking.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalculate_metrics\u001b[39m(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ivantrue/Desktop/Git/ProjectX_Algo/Models_with_stacking.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     ticker, label_period\u001b[39m=\u001b[39m\u001b[39m9\u001b[39m, label_threshold\u001b[39m=\u001b[39m\u001b[39m0.02\u001b[39m, feature_lags\u001b[39m=\u001b[39m[\u001b[39m3\u001b[39m, \u001b[39m6\u001b[39m, \u001b[39m9\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ivantrue/Desktop/Git/ProjectX_Algo/Models_with_stacking.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m ):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ivantrue/Desktop/Git/ProjectX_Algo/Models_with_stacking.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ivantrue/Desktop/Git/ProjectX_Algo/Models_with_stacking.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m    Calculate a variety of metrics for a given stock ticker, including moving averages, rate of change (ROC),\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ivantrue/Desktop/Git/ProjectX_Algo/Models_with_stacking.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m    on-balance volume (OBV), and the relative strength index (RSI). Also calculates lagged versions of these metrics\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ivantrue/Desktop/Git/ProjectX_Algo/Models_with_stacking.ipynb#X11sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m        pandas.DataFrame: A DataFrame with the calculated metrics and labels.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ivantrue/Desktop/Git/ProjectX_Algo/Models_with_stacking.ipynb#X11sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ivantrue/Desktop/Git/ProjectX_Algo/Models_with_stacking.ipynb#X11sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39mfresh_data.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, parse_dates\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, index_col\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ivantrue/Desktop/Git/ProjectX_Algo/Models_with_stacking.ipynb#X11sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39m# Calculate the percentage change over the given period\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ivantrue/Desktop/Git/ProjectX_Algo/Models_with_stacking.ipynb#X11sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     df[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mticker\u001b[39m}\u001b[39;00m\u001b[39m_pct_change\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m (\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ivantrue/Desktop/Git/ProjectX_Algo/Models_with_stacking.ipynb#X11sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m         df[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mticker\u001b[39m}\u001b[39;00m\u001b[39m_Close\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ivantrue/Desktop/Git/ProjectX_Algo/Models_with_stacking.ipynb#X11sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m         \u001b[39m.\u001b[39mpct_change(periods\u001b[39m=\u001b[39mlabel_period)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ivantrue/Desktop/Git/ProjectX_Algo/Models_with_stacking.ipynb#X11sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m         \u001b[39m.\u001b[39mshift(periods\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mlabel_period)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ivantrue/Desktop/Git/ProjectX_Algo/Models_with_stacking.ipynb#X11sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'fresh_data.csv'"
     ]
    }
   ],
   "source": [
    "def calculate_metrics(\n",
    "    ticker, label_period=9, label_threshold=0.02, feature_lags=[3, 6, 9]\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculate a variety of metrics for a given stock ticker, including moving averages, rate of change (ROC),\n",
    "    on-balance volume (OBV), and the relative strength index (RSI). Also calculates lagged versions of these metrics\n",
    "    based on the `lags` input.\n",
    "\n",
    "    Args:\n",
    "        ticker (str): The stock ticker to calculate metrics for.\n",
    "        period (int): The period to use for calculating metrics.\n",
    "        threshold (float): The threshold to use for calculating metrics.\n",
    "        lags (list of int): The lag periods to use for calculating lagged metrics.\n",
    "        refresh (bool, optional): Whether to refresh the data. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame with the calculated metrics and labels.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(\"fresh_data.csv\", parse_dates=True, index_col=0)\n",
    "\n",
    "    # Calculate the percentage change over the given period\n",
    "    df[f\"{ticker}_pct_change\"] = (\n",
    "        df[f\"{ticker}_Close\"]\n",
    "        .pct_change(periods=label_period)\n",
    "        .shift(periods=-label_period)\n",
    "    )\n",
    "\n",
    "    # Create a new column for the labels and initially set all labels to 0\n",
    "    df[f\"{ticker}_label\"] = 0\n",
    "\n",
    "    # Assign labels based on the threshold\n",
    "    df.loc[df[f\"{ticker}_pct_change\"] > label_threshold, f\"{ticker}_label\"] = 1\n",
    "    df.loc[df[f\"{ticker}_pct_change\"] < -label_threshold, f\"{ticker}_label\"] = -1\n",
    "\n",
    "    # Drop the percentage change column as it's no longer needed\n",
    "    df = df.dropna(subset=[f\"{ticker}_pct_change\"])\n",
    "\n",
    "    metrics_df = pd.DataFrame()\n",
    "\n",
    "    # Calculate base metrics\n",
    "    rsi = ta.momentum.RSIIndicator(df[f\"{ticker}_Close\"], window=14).rsi()\n",
    "    metrics_df[f\"{ticker}_RSI\"] = rsi.shift(periods=1)\n",
    "\n",
    "    rolling_std_shifted = (\n",
    "        df[f\"{ticker}_Close\"].rolling(window=20).std().shift(periods=1)\n",
    "    )\n",
    "    metrics_df[f\"{ticker}_Bollinger_Up\"] = (\n",
    "        df[f\"{ticker}_Close\"].rolling(window=20).mean().shift(periods=1)\n",
    "        + 2 * rolling_std_shifted\n",
    "    )\n",
    "    metrics_df[f\"{ticker}_Bollinger_Down\"] = (\n",
    "        df[f\"{ticker}_Close\"].rolling(window=20).mean().shift(periods=1)\n",
    "        - 2 * rolling_std_shifted\n",
    "    )\n",
    "\n",
    "    adx = talib.ADX(\n",
    "        df[f\"{ticker}_High\"], df[f\"{ticker}_Low\"], df[f\"{ticker}_Close\"], timeperiod=14\n",
    "    )\n",
    "    metrics_df[f\"{ticker}_ADX\"] = adx.shift(periods=1)\n",
    "\n",
    "    macd_line, signal_line, _ = talib.MACD(\n",
    "        df[f\"{ticker}_Close\"], fastperiod=12, slowperiod=26, signalperiod=9\n",
    "    )\n",
    "    metrics_df[f\"{ticker}_MACD\"] = (macd_line - signal_line).shift(periods=1)\n",
    "\n",
    "    obv = ta.volume.OnBalanceVolumeIndicator(\n",
    "        df[f\"{ticker}_Close\"], df[f\"{ticker}_Volume\"]\n",
    "    ).on_balance_volume()\n",
    "    metrics_df[f\"{ticker}_OBV\"] = obv.shift(periods=1)\n",
    "\n",
    "    # Calculate lagged metrics\n",
    "    for lag in feature_lags:\n",
    "        # Use shift to create lagged features, to avoid looking ahead in time\n",
    "        metrics_df[f\"{ticker}_Delta_ADX_{lag}\"] = adx.diff(lag).shift(periods=1)\n",
    "\n",
    "        metrics_df[f\"{ticker}_MA_{lag}\"] = (\n",
    "            df[f\"{ticker}_Close\"].rolling(window=lag).mean().shift(periods=1)\n",
    "        )\n",
    "        metrics_df[f\"{ticker}_ROC_{lag}\"] = talib.ROC(\n",
    "            df[f\"{ticker}_Close\"], timeperiod=lag\n",
    "        ).shift(periods=1)\n",
    "        metrics_df[f\"{ticker}_OBV_ROC_{lag}\"] = obv.pct_change(periods=lag).shift(\n",
    "            periods=1\n",
    "        )\n",
    "        metrics_df[f\"{ticker}_Delta_RSI_{lag}\"] = rsi.diff(lag).shift(periods=1)\n",
    "\n",
    "        other_tickers = [\n",
    "            col[:-6]\n",
    "            for col in df.columns\n",
    "            if col.endswith(\"_Close\") and col != f\"{ticker}_Close\"\n",
    "        ]\n",
    "        other_ma_lag = pd.concat(\n",
    "            [\n",
    "                df[f\"{other_ticker}_Close\"]\n",
    "                .pct_change()\n",
    "                .rolling(window=lag)\n",
    "                .mean()\n",
    "                .shift(periods=1)\n",
    "                for other_ticker in other_tickers\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        metrics_df[f\"Market_MA_{lag}\"] = other_ma_lag.mean(axis=1)\n",
    "\n",
    "    # Handle missing values\n",
    "    metrics_df = metrics_df.replace([np.inf, -np.inf], np.nan)\n",
    "    metrics_df.dropna(inplace=True)\n",
    "\n",
    "    final_df = metrics_df.join(df[f\"{ticker}_label\"])\n",
    "\n",
    "    # # Validate data types\n",
    "    assert set(final_df.dtypes) <= {\n",
    "        np.dtype(\"float64\"),\n",
    "        np.dtype(\"int64\"),\n",
    "    }, \"Unexpected data types in DataFrame\"\n",
    "\n",
    "    return final_df\n",
    "\n",
    "\n",
    "calculate_metrics(\"AAPL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_and_Y_for_ML(ticker, label_period=9, label_threshold=0.02, feature_lags=[3, 6, 9], days_back = 30, refresh=False):\n",
    "    \n",
    "    if refresh:\n",
    "        retrieve_save_combined_data()\n",
    "    \n",
    "    df = calculate_metrics(\n",
    "        ticker, label_period=label_period, label_threshold=label_threshold, feature_lags=feature_lags)\n",
    "\n",
    "    X = df.drop(columns=[f\"{ticker}_label\"])\n",
    "    Y = df[f\"{ticker}_label\"].copy()\n",
    "\n",
    "    # Use all data except last day for training, and last day for testing\n",
    "    X_train, X_test, Y_train, Y_test = X[:-days_back], X[-days_back:], Y[:-days_back], Y[-days_back:]\n",
    "\n",
    "    # X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25)\n",
    "\n",
    "    # X_train, X_test, Y_train, Y_test = X_train.values, X_test.values, Y_train.values, Y_test.values\n",
    "\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = X_and_Y_for_ML(\"AAPL\", label_period=9, label_threshold=0.022, days_back=5)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.41702586, 0.23706897, 0.22437972, 0.28263215, 0.4368932 ]),\n",
       " 0.31959997954097386)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_best_params = {\n",
    "    'bootstrap': False,\n",
    "    'max_depth': 30,\n",
    "    'min_samples_leaf': 1,\n",
    "    'min_samples_split': 2,\n",
    "    'n_estimators': 300\n",
    "}\n",
    "\n",
    "random_forest = Pipeline([\n",
    "    (\"model\", RandomForestClassifier(**random_forest_best_params, random_state=1))\n",
    "])\n",
    "random_forest.fit(X_train, Y_train)\n",
    "\n",
    "predictions = random_forest.predict(X_test)\n",
    "\n",
    "accuracy = cross_val_score(random_forest, X_train, Y_train, n_jobs=-1, cv=5)\n",
    "\n",
    "accuracy, accuracy.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.4137931 , 0.24892241, 0.23840345, 0.29989213, 0.39805825]),\n",
       " 0.3198138693598185)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosting_best_params = {'learning_rate': 0.2,\n",
    "  'max_depth': 7,\n",
    "  'n_estimators': 300}\n",
    "\n",
    "boosting_model = Pipeline([\n",
    "        (\"model\", GradientBoostingClassifier(**boosting_best_params, random_state=1))])\n",
    "\n",
    "\n",
    "accuracy = cross_val_score(boosting_model, X_train, Y_train, n_jobs=-1, cv=5)\n",
    "\n",
    "accuracy, accuracy.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.37823276, 0.31681034, 0.31499461, 0.30636462, 0.43257821]),\n",
       " 0.34979610720529697)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC_best_params = {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
    "\n",
    "SVC_model = Pipeline([\n",
    "        (\"trans\", StandardScaler()),\n",
    "        (\"model\", SVC(**SVC_best_params, random_state=1, probability=True))\n",
    "    ])\n",
    "\n",
    "accuracy = cross_val_score(SVC_model, X_train, Y_train, n_jobs=-1, cv=5)\n",
    "accuracy, accuracy.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best K nearest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.39978448, 0.30818966, 0.31067961, 0.29341963, 0.43473571]),\n",
       " 0.349361817877469)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_best_params = {'algorithm': 'auto',\n",
    "  'leaf_size': 20,\n",
    "  'n_neighbors': 3,\n",
    "  'weights': 'distance'}\n",
    "\n",
    "K_model = Pipeline([\n",
    "        (\"trans\", StandardScaler()),\n",
    "        (\"model\", KNeighborsClassifier(**K_best_params))\n",
    "    ])\n",
    "\n",
    "accuracy = cross_val_score(K_model, X_train, Y_train, n_jobs=-1, cv=5)\n",
    "accuracy, accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = {\n",
    "#     # Random Forest..was here \n",
    "\n",
    "# #     \"Gradient_boosting\": Pipeline([\n",
    "# #         (\"model\", GradientBoostingClassifier(),\n",
    "# #   )]),\n",
    "#     # \"SVClass\": Pipeline([\n",
    "#     #     (\"trans\", StandardScaler()),\n",
    "#     #     (\"model\", SVC())\n",
    "#     # ]),\n",
    "# #     \"Neighbors\" : Pipeline([\n",
    "# #         (\"trans\", StandardScaler()),\n",
    "# #         (\"model\", KNeighborsClassifier())\n",
    "# #     ])\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create an empty DataFrame to store the results\n",
    "scores_df = pd.DataFrame()\n",
    "\n",
    "# loop through the models dictionary\n",
    "for model_name, model in models.items():\n",
    "    # calculate the cross validation scores for the current model\n",
    "    scores = cross_val_score(model, X_train, Y_train, scoring=\"accuracy\", cv=5, n_jobs=-1)\n",
    "    \n",
    "    # create a temporary DataFrame to hold the scores\n",
    "    temp_df = pd.DataFrame({model_name: scores})\n",
    "\n",
    "    # add the results to the main DataFrame\n",
    "    scores_df = pd.concat([scores_df, temp_df], axis=1)\n",
    "\n",
    "# calculate the mean score for each fold\n",
    "scores_df = scores_df.T  # Transpose the DataFrame so that the models are the index\n",
    "scores_df.columns = [f'Fold_{i+1}_Score' for i in range(scores_df.shape[1])]  # Rename columns to Fold_1_Score, Fold_2_Score, etc.\n",
    "scores_df['Mean_Score'] = scores_df.mean(axis=1)  # Calculate the mean score for each model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the DataFrame\n",
    "scores_df.sort_values(by=\"Mean_Score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# param_grid_SVClass = {\n",
    "#     'model__C': [1, 10, 100],  # regularization parameter\n",
    "#     'model__gamma': [1, 0.1],  # kernel coefficient\n",
    "#     'model__kernel': ['rbf', 'poly', 'sigmoid']  # type of hyperplane used to separate the data\n",
    "# }\n",
    "\n",
    "# param_grid_Gradient_boosting = {\n",
    "#       # loss function to be optimized\n",
    "#     'model__learning_rate': [0.2, 0.1, 0.01],  # learning rate shrinks the contribution of each tree\n",
    "#     'model__n_estimators': [100, 200, 300],  # the number of boosting stages to perform\n",
    "#     'model__max_depth': [None, 3, 7],  # maximum depth of the individual regression estimators\n",
    "# }\n",
    "\n",
    "\n",
    "# param_grid_Neighbors = {\n",
    "#     'model__n_neighbors': [3, 7, 15],\n",
    "#     'model__weights': ['uniform', 'distance'],\n",
    "#     'model__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "#     'model__leaf_size': [20, 30, 40],\n",
    "# }\n",
    "\n",
    "\n",
    "# param_grid_Random_forest = {\n",
    "#     'model__n_estimators': [100, 200, 300],\n",
    "#     'model__max_depth': [None, 10, 30],\n",
    "#     'model__min_samples_split': [2, 5, 10],\n",
    "#     'model__min_samples_leaf': [1, 2, 4],\n",
    "#     'model__bootstrap': [True, False],\n",
    "# }\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    param_grid_name = f\"param_grid_{model_name}\"  \n",
    "    param_grid = globals()[param_grid_name]  # Access the parameter grid using the variable name\n",
    "    \n",
    "    grid_search = GridSearchCV(model, param_grid=param_grid, scoring=\"accuracy\", cv=5, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train, Y_train)  # Make sure you have defined X_train and Y_train\n",
    "    \n",
    "    best_params[model_name] = grid_search.best_params_\n",
    "\n",
    "for model_name, params in best_params.items():\n",
    "    print(f\"Best parameters for {model_name}:\", params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bildong final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('SVC', SVC_model),\n",
    "        ('K_near', K_model),\n",
    "        ('Random_forest', random_forest),\n",
    "        ('boosting_model', boosting_model)\n",
    "    ],\n",
    "    final_estimator=RandomForestClassifier(random_state=43),\n",
    "    cv=5, n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time= 3.8min\n",
      "[CV] END .................................................... total time= 3.8min\n",
      "[CV] END .................................................... total time= 3.8min\n",
      "[CV] END .................................................... total time= 3.8min\n",
      "[CV] END .................................................... total time= 3.8min\n",
      "[0.34375    0.41163793 0.399137   0.39482201 0.35167206]\n",
      "0.38020379979912955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  3.8min finished\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(stacking_clf, X_train, Y_train, scoring='accuracy', verbose=2, n_jobs=-1, cv = 5)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stacking_clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m stacking_clf\u001b[39m.\u001b[39mfit(X_train, Y_train)\n\u001b[1;32m      3\u001b[0m predictions_final \u001b[39m=\u001b[39m stacking_clf\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m      5\u001b[0m predictions_final\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stacking_clf' is not defined"
     ]
    }
   ],
   "source": [
    "stacking_clf.fit(X_train, Y_train)\n",
    "\n",
    "predictions_final = stacking_clf.predict(X_test)\n",
    "\n",
    "predictions_final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
